#!/usr/bin/env python

import os, sys
import boto3
import readline
from argparse import ArgumentParser
import subprocess
import itertools
import logging
import time

ec2 = boto3.resource('ec2')
as_client = boto3.client('autoscaling')
elb_client = boto3.client('elbv2')
s3 = boto3.resource('s3')
s3_client = boto3.client('s3')
as_client = boto3.client('autoscaling')


# TODO document aws policy needed.
# S3-compiler-explorer-acces seems to be fairly minimal. XaniaBlog seems too open

def target_group_arn_for(args):
    if args['env'] == 'prod':
        return 'arn:aws:elasticloadbalancing:us-east-1:052730242331:targetgroup/GccExplorerNodes/84e7c7626fd50397'
    else:
        return 'arn:aws:elasticloadbalancing:us-east-1:052730242331:targetgroup/Beta/07d45244520b84c4'


# TODO connect timeout on SSH and handle more gracefully
def run_remote(instance, command):
    # print "Running '{}' on {}".format(" ".join(command), instance)
    os.system(
        'ssh -o ConnectTimeout=2 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o LogLevel=ERROR ubuntu@{} -- {}'.format(
            instance.instance.public_ip_address, " ".join(command)))


def exec_remote(instance, command):
    # TODO properlogging
    # print "Running '{}' on {}".format(" ".join(command), instance)
    return subprocess.check_output(
        ['ssh', '-o', 'ConnectTimeout=2', '-o', 'UserKnownHostsFile=/dev/null', '-o', 'StrictHostKeyChecking=no',
         '-o', 'LogLevel=ERROR',
         'ubuntu@' + instance.instance.public_ip_address, '--'] + ["'{}'".format(c) for c in command])


class Instance(object):
    def __init__(self, health, group_arn):
        self.group_arn = group_arn
        self.instance = ec2.Instance(id=health['Target']['Id'])
        self.instance.load()
        self.elb_health = health['TargetHealth']['State']
        self.service_status = {key: value for key, value in
                               (s.split("=", 1) for s in
                                exec_remote(self, ['sudo', 'systemctl', 'show', 'compiler-explorer']).split("\n") if
                                "=" in s)}
        self.running_version = exec_remote(self, [
            'bash', '-c',
            'if [[ -f /compiler-explorer-image/.deploy/s3_key ]]; then cat /compiler-explorer-image/.deploy/s3_key; fi'
        ]).strip()

    def __str__(self):
        return '%s' % self.instance

    def describe_autoscale(self):
        results = as_client.describe_auto_scaling_instances(InstanceIds=[self.instance.instance_id])
        return results['AutoScalingInstances'][0]

    def update_elb_health(self):
        health = elb_client.describe_target_health(
            TargetGroupArn=self.group_arn,
            Targets=[{'Id': self.instance.instance_id}])['TargetHealthDescriptions'][0]
        self.elb_health = health['TargetHealth']['State']

    @staticmethod
    def elb_instances(group_arn):
        return [Instance(health, group_arn) for health in
                elb_client.describe_target_health(TargetGroupArn=group_arn)['TargetHealthDescriptions']]


def print_instances(instances, number=False):
    STATUS_FORMAT = '{: <16} {: <20} {: <10} {: <12} {: <11} {: <11} {: <14}'
    if number:
        print '   ',
    releases = get_releases()
    print STATUS_FORMAT.format('Address', 'Instance Id', 'State', 'Type', 'ELB', 'Service', 'Version')
    count = 0
    for inst in instances:
        if number:
            print '{: <3}'.format(count),
        count += 1
        running_version = release_for(releases, inst.running_version)
        if running_version:
            running_version = '{} ({})'.format(running_version.version, running_version.branch)
        else:
            running_version = '(unknown {})'.format(inst.running_version)
        print STATUS_FORMAT.format(
            inst.instance.public_ip_address,
            inst.instance.id,
            inst.instance.state['Name'],
            inst.instance.instance_type,
            inst.elb_health,
            inst.service_status['SubState'],
            running_version)


def status_cmd(args):
    print_instances(Instance.elb_instances(target_group_arn_for(args)), number=False)


def pick_instance(args):
    instances = Instance.elb_instances(target_group_arn_for(args))
    if len(instances) == 1:
        return instances[0]
    while True:
        print_instances(instances, number=True)
        inst = raw_input('Which instance? ')
        try:
            return instances[int(inst)]
        except:
            pass


def pick_instances(args):
    # TODO, maybe something in args to select only some?
    return Instance.elb_instances(target_group_arn_for(args))


def login_cmd(args):
    instance = pick_instance(args)
    run_remote(instance, [])


class Hash(object):
    def __init__(self, hash):
        self.hash = hash

    def __repr__(self):
        return self.hash

    def __str__(self):
        return self.hash[:6] + ".." + self.hash[-6:]


class Release(object):
    def __init__(self, version, branch, key, size, hash):
        self.version = version
        self.branch = branch
        self.key = key
        self.size = size
        self.hash = hash

    def __repr__(self):
        return 'Release({}, {}, {}, {}, {})'.format(self.version, self.branch, self.key, self.size, self.hash)


def sizeof_fmt(num, suffix='B'):
    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:
        if abs(num) < 1024.0:
            return "%3.1f%s%s" % (num, unit, suffix)
        num /= 1024.0
    return "%.1f%s%s" % (num, 'Yi', suffix)


def list_cmd(args):
    current = get_current_key(args)
    releases = get_releases()
    RELEASE_FORMAT = '{: <5} {: <10} {: <10} {: <10} {: <14}'
    print RELEASE_FORMAT.format('Live', 'Branch', 'Version', 'Size', 'Hash')
    for branch, releases in itertools.groupby(releases, lambda r: r.branch):
        for release in releases:
            print RELEASE_FORMAT.format(
                ' -->' if release.key == current else '',
                release.branch, release.version, sizeof_fmt(release.size), release.hash)


def branch_for_env(args):
    if args['env'] == 'prod':
        return 'release'
    elif args['env'] == 'beta':
        return 'beta'
    else:
        return 'master'


def version_key_for_env(env):
    return 'version/{}'.format(branch_for_env(env))


def get_current_key(args):
    try:
        o = s3_client.get_object(
            Bucket='compiler-explorer',
            Key=version_key_for_env(args)
        )
        return o['Body'].read().strip()
    except s3_client.exceptions.NoSuchKey:
        return None


def set_current_key(args, key):
    s3_key = version_key_for_env(args)
    print 'Setting {} to {}'.format(s3_key, key)
    s3_client.put_object(
        Bucket='compiler-explorer',
        Key=s3_key,
        Body=key,
        ACL='public-read'
    )


def release_for(releases, s3_key):
    for r in releases:
        if r.key == s3_key:
            return r
    return None


def current_cmd(args):
    current = get_current_key(args)
    if not current:
        print "No current version set"
        return
    r = release_for(get_releases(), current)
    if r:
        print r
    else:
        print "Non-standard release with s3 key '{}'".format(current)


def get_releases():
    paginator = s3_client.get_paginator('list_objects_v2')
    PREFIX = 'dist/travis/'
    result_iterator = paginator.paginate(
        Bucket='compiler-explorer',
        Prefix=PREFIX
    )
    releases = []
    for result in result_iterator.search('[Contents][]'):
        key = result['Key']
        if not key.endswith(".tar.xz"):
            continue
        split_key = key.split('/')
        branch = split_key[-2]
        version = split_key[-1].split('.')[0]
        size = result['Size']
        info_key = "/".join(split_key[:-1]) + "/" + version + ".txt"
        o = s3_client.get_object(
            Bucket='compiler-explorer',
            Key=info_key
        )
        hash = o['Body'].read().strip()
        releases.append(Release(int(version), branch, key, size, Hash(hash)))
    return releases


def find_release(version):
    for r in get_releases():
        if r.version == version:
            return r
    return None


def wait_for_autoscale_state(instance, state):
    logging.info("Waiting for {} to reach autoscale lifecycle '{}'...".format(instance, state))
    while True:
        cur_state = instance.describe_autoscale()['LifecycleState']
        logging.debug("State is {}".format(cur_state));
        if cur_state == state:
            logging.info("...done")
            return
        time.sleep(5)


def wait_for_elb_state(instance, state):
    logging.info("Waiting for {} to reach ELB state '{}'...".format(instance, state))
    while True:
        instance.update_elb_health()
        logging.debug("State is {}".format(instance.elb_health));
        if instance.elb_health == state:
            logging.info("...done")
            return
        time.sleep(5)


def restart_cmd(args):
    # TODO are you sure in prod
    # TODO handle "nice" draining instead of just doing them all straight away.
    # TODO needs to work with load balancers etc.
    for instance in pick_instances(args):
        logging.info("Restarting {}...".format(instance))
        instance_id = instance.instance.instance_id
        as_group = instance.describe_autoscale()
        if as_group['LifecycleState'] != 'InService':
            logging.error("Skipping {} as it is not InService ({})".format(instance, as_group))
            continue
        logging.info("Putting {} into standby".format(instance))
        # TODO decrement desired capacity if wouldn't go below minimum?
        as_client.enter_standby(
            InstanceIds=[instance_id],
            AutoScalingGroupName=as_group['AutoScalingGroupName'],
            ShouldDecrementDesiredCapacity=True)
        wait_for_autoscale_state(instance, 'Standby')
        logging.info("Restarting service on {}".format(instance))
        run_remote(instance, ['sudo', 'systemctl', 'restart', 'compiler-explorer'])
        logging.info("Moving {} out of standby".format(instance))
        as_client.exit_standby(
            InstanceIds=[instance_id],
            AutoScalingGroupName=as_group['AutoScalingGroupName'])
        wait_for_autoscale_state(instance, 'InService')
        wait_for_elb_state(instance, 'healthy')
        # maybe use instance protection?


def set_current_cmd(args):
    if args['raw']:
        to_set = args['version']
    else:
        release = find_release(int(args['version']))
        if not release:
            print "Unable to find version " + args.version
            sys.exit(1)
        print 'Found release {}'.format(release)
        to_set = release.key
    set_current_key(args, to_set)
    # TODO, ideally sync the versioned directory here, requires remote machine


if __name__ == '__main__':
    parser = ArgumentParser(description='Administrate Compiler Explorer instances')
    parser.add_argument('--env', choices=['prod', 'beta'], default='prod')
    parser.add_argument('--debug', action='store_true')
    subparsers = parser.add_subparsers(dest='command')
    list_parser = subparsers.add_parser('list')
    status_parser = subparsers.add_parser('status')
    login_parser = subparsers.add_parser('login')
    start_parser = subparsers.add_parser('start')
    stop_parser = subparsers.add_parser('stop')
    restart_parser = subparsers.add_parser('restart')
    current_parser = subparsers.add_parser('current')
    set_current = subparsers.add_parser('set_current')
    set_current.add_argument('version', help='version to set')
    set_current.add_argument('--raw', action='store_true', help='set a raw path for a version')
    kwargs = vars(parser.parse_args())
    if kwargs['debug']:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    globals()[kwargs.pop('command') + "_cmd"](kwargs)

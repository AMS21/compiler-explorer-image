#!/usr/bin/env python3
# coding=utf-8
import glob
import os
import sys
import shutil
import tempfile
from argparse import ArgumentParser
from cachecontrol import CacheControl
from cachecontrol.caches.file_cache import FileCache
import subprocess
import yaml
import requests
import logging


class InstallationContext(object):
    def __init__(self, destination, staging, s3_url, dry_run):
        self.destination = destination
        self.staging = staging
        self.s3_url = s3_url
        self.dry_run = dry_run
        self.fetcher = CacheControl(requests.session(), cache=FileCache(
            os.path.expanduser('~/.web_cache')))

    def debug(self, message):
        logging.debug(message)

    def info(self, message):
        logging.info(message)

    def warn(self, message):
        logging.warning(message)

    def error(self, message):
        logging.error(message)

    def clean_staging(self):
        self.debug(f"Cleaning staging dir {self.staging}")
        shutil.rmtree(self.staging, ignore_errors=True)
        subprocess.check_call(["rm", "-rf", self.staging])
        self.debug(f"Recreating staging dir {self.staging}")
        os.makedirs(self.staging)

    def fetch_to(self, url, fd):
        self.debug(f'Fetching {url}')
        request = self.fetcher.get(url, stream=True)
        if not request.ok:
            self.error(f'Failed to fetch {url}: {request}')
            raise RuntimeError('Fetch failure')
        fetched = 0
        length = int(request.headers['content-length'])
        self.info(f'Fetching {url} ({length} bytes)')
        for chunk in request.iter_content(chunk_size=16 * 1024 * 1024):
            fd.write(chunk)
            fetched += len(chunk)
            self.info(f'{100.0 * fetched / length:.1f}% of {url}...')
        fd.flush()

    def fetch_url_and_pipe_to(self, url, command):
        # We stream to a temporary file first before then piping this to the command
        # as sometimes the command can take so long the URL endpoint closes the door on us
        with tempfile.TemporaryFile() as fd:
            self.fetch_to(url, fd)
            fd.seek(0)
            self.info(f'Piping to {" ".join(command)}')
            subprocess.check_call(command, stdin=fd, cwd=self.staging)

    def fetch_s3_and_pipe_to(self, s3, command):
        return self.fetch_url_and_pipe_to(f'{self.s3_url}/{s3}', command)

    def move_from_staging(self, source, dest=None):
        if not dest:
            dest = source
        existing_dir_rename = os.path.join(self.staging, dest + ".orig")
        source = os.path.join(self.staging, source)
        dest = os.path.join(self.destination, dest)
        if self.dry_run:
            self.info(f'Would install {source} to {dest} but in dry-run mode')
            return
        self.info(f'Moving from staging ({source}) to final destination ({dest})')
        state = ''
        if os.path.isdir(dest):
            self.info(f'Destination exists, temporarily moving out of the way (to {existing_dir_rename}')
            os.rename(dest, existing_dir_rename)
            state = 'old_renamed'
        try:
            os.rename(source, dest)
            if state == 'old_renamed':
                state = 'old_needs_remove'
        finally:
            if state == 'old_needs_remove':
                self.debug(f'Removing temporarily moved {existing_dir_rename}')
                shutil.rmtree(existing_dir_rename, ignore_errors=True)
            elif state == 'old_renamed':
                self.warn(f'Moving old destination back')
                os.rename(existing_dir_rename, dest)

    def compare_against_staging(self, source, dest=None):
        if not dest:
            dest = source
        source = os.path.join(self.staging, source)
        dest = os.path.join(self.destination, dest)
        self.info(f'Comparing {source} vs {dest}...')
        result = subprocess.call(['diff', '-r', source, dest])
        if result == 0:
            self.info('Contents match')
        else:
            self.warn('Contents differ')
        return result == 0

    def check_output(self, args):
        args = args[:]
        args[0] = os.path.join(self.destination, args[0])
        return subprocess.check_output(args).decode('utf-8')


class Installable(object):
    def __init__(self, context, name, depends):
        self.context = context
        self.name = name
        if not depends:
            depends = []
        self.depends = depends

    def debug(self, message):
        self.context.debug(f'{self.name}: {message}')

    def info(self, message):
        self.context.info(f'{self.name}: {message}')

    def warn(self, message):
        self.context.warn(f'{self.name}: {message}')

    def error(self, message):
        self.context.error(f'{self.name}: {message}')

    def verify(self):
        return True

    def is_installed(self):
        raise RuntimeError("needs to be implemented")

    def install(self):
        self.debug("Ensuring dependees are installed")
        any_missing = False
        for dependee in self.depends:
            if not dependee.is_installed():
                self.warn("Required dependee {} not installed".format(dependee))
                any_missing = True
        if any_missing:
            return False
        self.debug("Dependees ok")
        return True

    def install_internal(self):
        raise RuntimeError("needs to be implemented")


class S3TarballInstallable(Installable):
    def __init__(self, context, name, path_name, check_call, depends=None):
        super(S3TarballInstallable, self).__init__(context, name, depends)
        self.path_name = path_name
        self.check_call = check_call

    def stage(self):
        self.context.clean_staging()
        self.context.fetch_s3_and_pipe_to(f'{self.path_name}.tar.xz', ['tar', 'Jxf', '-'])

    def verify(self):
        if not super(S3TarballInstallable, self).verify():
            return False
        self.stage()
        return self.context.compare_against_staging(self.path_name)

    def is_installed(self):
        try:
            res = self.context.check_output(self.check_call)
            self.debug(f'Check call returned {res}')
            return True
        except FileNotFoundError:
            self.debug(f'File not found for {self.check_call}')
            return False
        except subprocess.CalledProcessError:
            self.debug(f'Got an error for {self.check_call}')
            return False

    def install(self):
        if not super(S3TarballInstallable, self).install():
            return False
        self.stage()
        self.context.move_from_staging(self.path_name)
        return True

    def __repr__(self) -> str:
        return f'S3TarballInstallable({self.name}, {self.path_name})'


def parse(install_context, installables, context, nodes):
    for name, node in nodes.items():
        node_context = f'{context}/{name}'
        if 'type' not in node:
            return parse(install_context, installables, node_context, node)
        type = node['type']
        if type == 's3tarballs':
            check_exe_base = node['check_exe'].split(" ")
            for target in node['targets']:
                path_name = f'{name}-{target}'
                check_exe = check_exe_base[:]
                check_exe[0] = os.path.join(path_name, check_exe[0])
                installables.append(
                    S3TarballInstallable(install_context, f'{node_context} {target}', path_name, check_exe))
        else:
            raise RuntimeError(f'Bad type {type} for {node_context}')


def filter_match(filter, installable):
    return filter in installable.name


if __name__ == '__main__':
    parser = ArgumentParser(description='Install binaries, libraries and compilers for Compiler Explorer')
    parser.add_argument('--dest', default='/opt/compiler-explorer', metavar='DEST',
                        help='install with DEST as the installation root (default %(default)s)')
    parser.add_argument('--staging-dir', default='/opt/compiler-explorer/staging', metavar='STAGEDIR',
                        help='install to STAGEDIR then rename in-place. Must be on the same drive as DEST for atomic'
                             'rename/replace. Directory will be removed during install (default %(default)s)')

    parser.add_argument('--s3_bucket', default='compiler-explorer', metavar='BUCKET',
                        help='look for S3 resources in BUCKET (default %(default)s)')
    parser.add_argument('--s3_dir', default='opt', metavar='DIR',
                        help='look for S3 resources in the bucket\'s subdirectory DIR (default %(default)s)')
    parser.add_argument('--yaml_dir', default=os.path.join(os.path.dirname(os.path.realpath(__file__)), 'yaml'),
                        help='look for installation yaml files in DIR (default %(default)s', metavar='DIR')
    parser.add_argument('--dry_run', default=False, action='store_true', help='dry run only')
    parser.add_argument('--debug', default=False, action='store_true', help='log at debug')
    parser.add_argument('command', choices=['list', 'install', 'check_installed', 'verify'], default='list',
                        nargs='?')
    parser.add_argument('filter', nargs='*', help='filter to apply', default=[])

    args = parser.parse_args()
    s3_url = f'https://s3.amazonaws.com/{args.s3_bucket}/{args.s3_dir}'
    context = InstallationContext(args.dest, args.staging_dir, s3_url, args.dry_run)

    # todo
    logging.basicConfig(filename='/tmp/ce_install.log', level=logging.DEBUG if args.debug else logging.INFO)

    installables = []
    for yamlfile in glob.glob(os.path.join(args.yaml_dir, '*.yaml')):
        parse(context, installables, "", yaml.load(open(yamlfile, 'r')))

    for filt in args.filter:
        installables = filter(lambda installable: filter_match(filt, installable), installables)

    if args.command == 'list':
        print("Installation candidates:")
        for installable in sorted(installables, key=lambda x: x.name):
            print(installable.name)
        sys.exit(0)
    elif args.command == 'verify':
        num_ok = 0
        num_not_ok = 0
        for installable in installables:
            print(f"Checking {installable.name}")
            if not installable.is_installed():
                context.info(f"{installable.name} is not installed")
                num_not_ok += 1
            elif not installable.verify():
                context.info(f"{installable.name} is not OK")
                num_not_ok += 1
            else:
                num_ok += 1
        print(f'{num_ok} packages OK, {num_not_ok} not OK or not installed')
        if num_not_ok:
            sys.exit(1)
        sys.exit(0)
    elif args.command == 'check_installed':
        for installable in installables:
            if installable.is_installed():
                print(f"{installable.name}: installed")
            else:
                print(f"{installable.name}: not installed")
        sys.exit(0)
    elif args.command == 'install':
        num_installed = 0
        num_skipped = 0
        num_failed = 0
        for installable in installables:
            print(f"Installing {installable.name}")
            if installable.is_installed():
                context.info(f"{installable.name} is already installed, skipping")
                num_skipped += 1
            else:
                if installable.install():
                    if not installable.is_installed():
                        context.error(f"{installable.name} installed OK, but doesn't appear as installed after")
                        num_failed += 1
                    else:
                        context.info(f"{installable.name} installed OK")
                        num_installed += 1
                else:
                    context.info(f"{installable.name} failed to install")
                    num_failed += 1
        print(f'{num_installed} packages installed OK, {num_skipped} skipped, and {num_failed} failed installation')
        if num_failed:
            sys.exit(1)
        sys.exit(0)
    else:
        raise RuntimeError("Er, whoops")
